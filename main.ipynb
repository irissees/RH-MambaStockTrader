{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3abab18f-ac4b-4736-9f97-b5b58d5d7ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: torch in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (2.5.1)\n",
      "Collecting argparse (from -r requirements.txt (line 5))\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (4.66.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: robin_stocks in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (3.2.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\themu\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\themu\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 4)) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\themu\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\users\\themu\\anaconda3\\lib\\site-packages (from robin_stocks->-r requirements.txt (line 8)) (2.32.2)\n",
      "Requirement already satisfied: pyotp in c:\\users\\themu\\anaconda3\\lib\\site-packages (from robin_stocks->-r requirements.txt (line 8)) (2.9.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\themu\\anaconda3\\lib\\site-packages (from robin_stocks->-r requirements.txt (line 8)) (0.21.0)\n",
      "Requirement already satisfied: cryptography in c:\\users\\themu\\anaconda3\\lib\\site-packages (from robin_stocks->-r requirements.txt (line 8)) (42.0.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from cryptography->robin_stocks->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from requests->robin_stocks->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from requests->robin_stocks->-r requirements.txt (line 8)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from requests->robin_stocks->-r requirements.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\themu\\anaconda3\\lib\\site-packages (from requests->robin_stocks->-r requirements.txt (line 8)) (2024.8.30)\n",
      "Requirement already satisfied: pycparser in c:\\users\\themu\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography->robin_stocks->-r requirements.txt (line 8)) (2.21)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68722e3a-6e48-4676-99d5-6102059172db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "\n",
    "import robin_stocks.robinhood as r\n",
    "from robin_stocks import *\n",
    "from datetime import datetime, time, date\n",
    "import pytz\n",
    "import requests,json\n",
    "from scipy import stats\n",
    "from dataclasses import dataclass\n",
    "from typing import Union\n",
    "import threading\n",
    "import time as t\n",
    "pst = pytz.timezone('US/Pacific')\n",
    "\n",
    "login = r.login(username='USERNAME', password='PASS') #robinhood account necessary for making trades and getting new data\n",
    "account = r.load_account_profile()\n",
    "\n",
    "current_date = datetime.now()#.date\n",
    "\n",
    "tickerList = ['AMZN','COST','GOOGL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a669e1d-b85f-4a52-a3f6-3592b6af9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def npo2(len):\n",
    "    \"\"\"\n",
    "    Returns the next power of 2 above len\n",
    "    \"\"\"\n",
    "\n",
    "    return 2 ** math.ceil(math.log2(len))\n",
    "\n",
    "def pad_npo2(X):\n",
    "    \"\"\"\n",
    "    Pads input length dim to the next power of 2\n",
    "\n",
    "    Args:\n",
    "        X : (B, L, D, N)\n",
    "\n",
    "    Returns:\n",
    "        Y : (B, npo2(L), D, N)\n",
    "    \"\"\"\n",
    "\n",
    "    len_npo2 = npo2(X.size(1))\n",
    "    pad_tuple = (0, 0, 0, 0, 0, len_npo2 - X.size(1))\n",
    "    return F.pad(X, pad_tuple, \"constant\", 0)\n",
    "\n",
    "class PScan(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def pscan(A, X):\n",
    "        # A : (B, D, L, N)\n",
    "        # X : (B, D, L, N)\n",
    "\n",
    "        # modifies X in place by doing a parallel scan.\n",
    "        # more formally, X will be populated by these values :\n",
    "        # H[t] = A[t] * H[t-1] + X[t] with H[0] = 0\n",
    "        # which are computed in parallel (2*log2(T) sequential steps (ideally), instead of T sequential steps)\n",
    "\n",
    "        # only supports L that is a power of two (mainly for a clearer code)\n",
    "        \n",
    "        B, D, L, _ = A.size()\n",
    "        num_steps = int(math.log2(L))\n",
    "\n",
    "        # up sweep (last 2 steps unfolded)\n",
    "        Aa = A\n",
    "        Xa = X\n",
    "        for _ in range(num_steps-2):\n",
    "            T = Xa.size(2)\n",
    "            Aa = Aa.view(B, D, T//2, 2, -1)\n",
    "            Xa = Xa.view(B, D, T//2, 2, -1)\n",
    "            \n",
    "            Xa[:, :, :, 1].add_(Aa[:, :, :, 1].mul(Xa[:, :, :, 0]))\n",
    "            Aa[:, :, :, 1].mul_(Aa[:, :, :, 0])\n",
    "\n",
    "            Aa = Aa[:, :, :, 1]\n",
    "            Xa = Xa[:, :, :, 1]\n",
    "\n",
    "        # we have only 4, 2 or 1 nodes left\n",
    "        if Xa.size(2) == 4:\n",
    "            Xa[:, :, 1].add_(Aa[:, :, 1].mul(Xa[:, :, 0]))\n",
    "            Aa[:, :, 1].mul_(Aa[:, :, 0])\n",
    "\n",
    "            Xa[:, :, 3].add_(Aa[:, :, 3].mul(Xa[:, :, 2] + Aa[:, :, 2].mul(Xa[:, :, 1])))\n",
    "        elif Xa.size(2) == 2:\n",
    "            Xa[:, :, 1].add_(Aa[:, :, 1].mul(Xa[:, :, 0]))\n",
    "            return\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        # down sweep (first 2 steps unfolded)\n",
    "        Aa = A[:, :, 2**(num_steps-2)-1:L:2**(num_steps-2)]\n",
    "        Xa = X[:, :, 2**(num_steps-2)-1:L:2**(num_steps-2)]\n",
    "        Xa[:, :, 2].add_(Aa[:, :, 2].mul(Xa[:, :, 1]))\n",
    "        Aa[:, :, 2].mul_(Aa[:, :, 1])\n",
    "\n",
    "        for k in range(num_steps-3, -1, -1):\n",
    "            Aa = A[:, :, 2**k-1:L:2**k]\n",
    "            Xa = X[:, :, 2**k-1:L:2**k]\n",
    "\n",
    "            T = Xa.size(2)\n",
    "            Aa = Aa.view(B, D, T//2, 2, -1)\n",
    "            Xa = Xa.view(B, D, T//2, 2, -1)\n",
    "\n",
    "            Xa[:, :, 1:, 0].add_(Aa[:, :, 1:, 0].mul(Xa[:, :, :-1, 1]))\n",
    "            Aa[:, :, 1:, 0].mul_(Aa[:, :, :-1, 1])\n",
    "\n",
    "    @staticmethod\n",
    "    def pscan_rev(A, X):\n",
    "        B, D, L, _ = A.size()\n",
    "        num_steps = int(math.log2(L))\n",
    "\n",
    "        # up sweep (last 2 steps unfolded)\n",
    "        Aa = A\n",
    "        Xa = X\n",
    "        for _ in range(num_steps-2):\n",
    "            T = Xa.size(2)\n",
    "            Aa = Aa.view(B, D, T//2, 2, -1)\n",
    "            Xa = Xa.view(B, D, T//2, 2, -1)\n",
    "                    \n",
    "            Xa[:, :, :, 0].add_(Aa[:, :, :, 0].mul(Xa[:, :, :, 1]))\n",
    "            Aa[:, :, :, 0].mul_(Aa[:, :, :, 1])\n",
    "\n",
    "            Aa = Aa[:, :, :, 0]\n",
    "            Xa = Xa[:, :, :, 0]\n",
    "\n",
    "        # we have only 4, 2 or 1 nodes left\n",
    "        if Xa.size(2) == 4:\n",
    "            Xa[:, :, 2].add_(Aa[:, :, 2].mul(Xa[:, :, 3]))\n",
    "            Aa[:, :, 2].mul_(Aa[:, :, 3])\n",
    "\n",
    "            Xa[:, :, 0].add_(Aa[:, :, 0].mul(Xa[:, :, 1].add(Aa[:, :, 1].mul(Xa[:, :, 2]))))\n",
    "        elif Xa.size(2) == 2:\n",
    "            Xa[:, :, 0].add_(Aa[:, :, 0].mul(Xa[:, :, 1]))\n",
    "            return\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        # down sweep (first 2 steps unfolded)\n",
    "        Aa = A[:, :, 0:L:2**(num_steps-2)]\n",
    "        Xa = X[:, :, 0:L:2**(num_steps-2)]\n",
    "        Xa[:, :, 1].add_(Aa[:, :, 1].mul(Xa[:, :, 2]))\n",
    "        Aa[:, :, 1].mul_(Aa[:, :, 2])\n",
    "\n",
    "        for k in range(num_steps-3, -1, -1):\n",
    "            Aa = A[:, :, 0:L:2**k]\n",
    "            Xa = X[:, :, 0:L:2**k]\n",
    "\n",
    "            T = Xa.size(2)\n",
    "            Aa = Aa.view(B, D, T//2, 2, -1)\n",
    "            Xa = Xa.view(B, D, T//2, 2, -1)\n",
    "\n",
    "            Xa[:, :, :-1, 1].add_(Aa[:, :, :-1, 1].mul(Xa[:, :, 1:, 0]))\n",
    "            Aa[:, :, :-1, 1].mul_(Aa[:, :, 1:, 0])\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, A_in, X_in):\n",
    "        L = X_in.size(1)\n",
    "\n",
    "        # cloning is requiered because of the in-place ops\n",
    "        if L == npo2(L):\n",
    "            A = A_in.clone()\n",
    "            X = X_in.clone()\n",
    "        else:\n",
    "            # pad tensors (and clone btw)\n",
    "            A = pad_npo2(A_in) # (B, npo2(L), D, N)\n",
    "            X = pad_npo2(X_in) # (B, npo2(L), D, N)\n",
    "        \n",
    "        # prepare tensors\n",
    "        A = A.transpose(2, 1) # (B, D, npo2(L), N)\n",
    "        X = X.transpose(2, 1) # (B, D, npo2(L), N)\n",
    "\n",
    "        # parallel scan (modifies X in-place)\n",
    "        PScan.pscan(A, X)\n",
    "\n",
    "        ctx.save_for_backward(A_in, X)\n",
    "        \n",
    "        # slice [:, :L] (cut if there was padding)\n",
    "        return X.transpose(2, 1)[:, :L]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output_in):\n",
    "        A_in, X = ctx.saved_tensors\n",
    "\n",
    "        L = grad_output_in.size(1)\n",
    "\n",
    "        # cloning is requiered because of the in-place ops\n",
    "        if L == npo2(L):\n",
    "            grad_output = grad_output_in.clone()\n",
    "            # the next padding will clone A_in\n",
    "        else:\n",
    "            grad_output = pad_npo2(grad_output_in) # (B, npo2(L), D, N)\n",
    "            A_in = pad_npo2(A_in) # (B, npo2(L), D, N)\n",
    "\n",
    "        # prepare tensors\n",
    "        grad_output = grad_output.transpose(2, 1)\n",
    "        A_in = A_in.transpose(2, 1) # (B, D, npo2(L), N)\n",
    "        A = torch.nn.functional.pad(A_in[:, :, 1:], (0, 0, 0, 1)) # (B, D, npo2(L), N) shift 1 to the left (see hand derivation)\n",
    "\n",
    "        # reverse parallel scan (modifies grad_output in-place)\n",
    "        PScan.pscan_rev(A, grad_output)\n",
    "\n",
    "        Q = torch.zeros_like(X)\n",
    "        Q[:, :, 1:].add_(X[:, :, :-1] * grad_output[:, :, 1:])\n",
    "\n",
    "        return Q.transpose(2, 1)[:, :L], grad_output.transpose(2, 1)[:, :L]\n",
    "    \n",
    "pscan = PScan.apply\n",
    "\n",
    "@dataclass\n",
    "class MambaConfig:\n",
    "    d_model: int # D\n",
    "    n_layers: int\n",
    "    dt_rank: Union[int, str] = 'auto'\n",
    "    d_state: int = 16 # N in paper/comments\n",
    "    expand_factor: int = 2 # E in paper/comments\n",
    "    d_conv: int = 4\n",
    "\n",
    "    dt_min: float = 0.001\n",
    "    dt_max: float = 0.1\n",
    "    dt_init: str = \"random\" # \"random\" or \"constant\"\n",
    "    dt_scale: float = 1.0\n",
    "    dt_init_floor = 1e-4\n",
    "\n",
    "    bias: bool = False\n",
    "    conv_bias: bool = True\n",
    "\n",
    "    pscan: bool = True # use parallel scan mode or sequential mode when training\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.d_inner = self.expand_factor * self.d_model \n",
    "\n",
    "        if self.dt_rank == 'auto':\n",
    "            self.dt_rank = math.ceil(self.d_model / 16)\n",
    "\n",
    "class Mamba(nn.Module):\n",
    "    def __init__(self, config: MambaConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.layers = nn.ModuleList([ResidualBlock(config) for _ in range(config.n_layers)])\n",
    "        self.norm_f = RMSNorm(config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.norm_f(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def step(self, x, caches):\n",
    "\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x, caches[i] = layer.step(x, caches[i])\n",
    "\n",
    "        return x, caches\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, config: MambaConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mixer = MambaBlock(config)\n",
    "        self.norm = RMSNorm(config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        output = self.mixer(self.norm(x)) + x\n",
    "        return output\n",
    "    \n",
    "    def step(self, x, cache):\n",
    "\n",
    "        output, cache = self.mixer.step(self.norm(x), cache)\n",
    "        output = output + x\n",
    "        return output, cache\n",
    "\n",
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self, config: MambaConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        # projects block input from D to 2*ED (two branches)\n",
    "        self.in_proj = nn.Linear(config.d_model, 2 * config.d_inner, bias=config.bias)\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=config.d_inner, out_channels=config.d_inner, \n",
    "                              kernel_size=config.d_conv, bias=config.conv_bias, \n",
    "                              groups=config.d_inner,\n",
    "                              padding=config.d_conv - 1)\n",
    "        \n",
    "        # projects x to input-dependent Δ, B, C\n",
    "        self.x_proj = nn.Linear(config.d_inner, config.dt_rank + 2 * config.d_state, bias=False)\n",
    "\n",
    "        # projects Δ from dt_rank to d_inner\n",
    "        self.dt_proj = nn.Linear(config.dt_rank, config.d_inner, bias=True)\n",
    "\n",
    "        # dt initialization\n",
    "        # dt weights\n",
    "        dt_init_std = config.dt_rank**-0.5 * config.dt_scale\n",
    "        if config.dt_init == \"constant\":\n",
    "            nn.init.constant_(self.dt_proj.weight, dt_init_std)\n",
    "        elif config.dt_init == \"random\":\n",
    "            nn.init.uniform_(self.dt_proj.weight, -dt_init_std, dt_init_std)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        # dt bias\n",
    "        dt = torch.exp(\n",
    "            torch.rand(config.d_inner) * (math.log(config.dt_max) - math.log(config.dt_min)) + math.log(config.dt_min)\n",
    "        ).clamp(min=config.dt_init_floor)\n",
    "        inv_dt = dt + torch.log(-torch.expm1(-dt)) \n",
    "        with torch.no_grad():\n",
    "            self.dt_proj.bias.copy_(inv_dt)\n",
    "\n",
    "        A = torch.arange(1, config.d_state + 1, dtype=torch.float32).repeat(config.d_inner, 1)\n",
    "        self.A_log = nn.Parameter(torch.log(A))\n",
    "        self.D = nn.Parameter(torch.ones(config.d_inner))\n",
    "\n",
    "\n",
    "        self.out_proj = nn.Linear(config.d_inner, config.d_model, bias=config.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        _, L, _ = x.shape\n",
    "\n",
    "        xz = self.in_proj(x) # (B, L, 2*ED)\n",
    "        x, z = xz.chunk(2, dim=-1) # (B, L, ED), (B, L, ED)\n",
    "\n",
    "        # x branch\n",
    "        x = x.transpose(1, 2) # (B, ED, L)\n",
    "        x = self.conv1d(x)[:, :, :L] # depthwise convolution over time, with a short filter\n",
    "        x = x.transpose(1, 2) # (B, L, ED)\n",
    "\n",
    "        x = F.silu(x)\n",
    "        y = self.ssm(x)\n",
    "\n",
    "        # z branch\n",
    "        z = F.silu(z)\n",
    "\n",
    "        output = y * z\n",
    "        output = self.out_proj(output) # (B, L, D)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def ssm(self, x):\n",
    "\n",
    "\n",
    "        A = -torch.exp(self.A_log.float()) # (ED, N)\n",
    "        D = self.D.float()\n",
    "\n",
    "        deltaBC = self.x_proj(x) \n",
    "\n",
    "        delta, B, C = torch.split(deltaBC, [self.config.dt_rank, self.config.d_state, self.config.d_state], dim=-1) # (B, L, dt_rank), (B, L, N), (B, L, N)\n",
    "        delta = F.softplus(self.dt_proj(delta)) # (B, L, ED)\n",
    "\n",
    "        if self.config.pscan:\n",
    "            y = self.selective_scan(x, delta, A, B, C, D)\n",
    "        else:\n",
    "            y = self.selective_scan_seq(x, delta, A, B, C, D)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def selective_scan(self, x, delta, A, B, C, D):\n",
    "\n",
    "        deltaA = torch.exp(delta.unsqueeze(-1) * A) # (B, L, ED, N)\n",
    "        deltaB = delta.unsqueeze(-1) * B.unsqueeze(2) # (B, L, ED, N)\n",
    "\n",
    "        BX = deltaB * (x.unsqueeze(-1)) # (B, L, ED, N)\n",
    "        \n",
    "        hs = pscan(deltaA, BX)\n",
    "\n",
    "        y = (hs @ C.unsqueeze(-1)).squeeze(3) # (B, L, ED, N) @ (B, L, N, 1) -> (B, L, ED, 1)\n",
    "\n",
    "        y = y + D * x\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def selective_scan_seq(self, x, delta, A, B, C, D):\n",
    "\n",
    "        _, L, _ = x.shape\n",
    "\n",
    "        deltaA = torch.exp(delta.unsqueeze(-1) * A) # (B, L, ED, N)\n",
    "        deltaB = delta.unsqueeze(-1) * B.unsqueeze(2) # (B, L, ED, N)\n",
    "\n",
    "        BX = deltaB * (x.unsqueeze(-1)) # (B, L, ED, N)\n",
    "\n",
    "        h = torch.zeros(x.size(0), self.config.d_inner, self.config.d_state, device=deltaA.device) # (B, ED, N)\n",
    "        hs = []\n",
    "\n",
    "        for t in range(0, L):\n",
    "            h = deltaA[:, t] * h + BX[:, t]\n",
    "            hs.append(h)\n",
    "            \n",
    "        hs = torch.stack(hs, dim=1) # (B, L, ED, N)\n",
    "\n",
    "        y = (hs @ C.unsqueeze(-1)).squeeze(3) # (B, L, ED, N) @ (B, L, N, 1) -> (B, L, ED, 1)\n",
    "\n",
    "        y = y + D * x\n",
    "\n",
    "        return y\n",
    "\n",
    "    def step(self, x, cache):\n",
    "        # x : (B, D)\n",
    "        # cache : (h, inputs)\n",
    "                # h : (B, ED, N)\n",
    "                # inputs : (B, ED, d_conv-1)\n",
    "        \n",
    "        # y : (B, D)\n",
    "        # cache : (h, inputs)\n",
    "        \n",
    "        h, inputs = cache\n",
    "        \n",
    "        xz = self.in_proj(x) # (B, 2*ED)\n",
    "        x, z = xz.chunk(2, dim=1) # (B, ED), (B, ED)\n",
    "\n",
    "        # x branch\n",
    "        x_cache = x.unsqueeze(2)\n",
    "        x = self.conv1d(torch.cat([inputs, x_cache], dim=2))[:, :, self.config.d_conv-1] # (B, ED)\n",
    "\n",
    "        x = F.silu(x)\n",
    "        y, h = self.ssm_step(x, h)\n",
    "\n",
    "        # z branch\n",
    "        z = F.silu(z)\n",
    "\n",
    "        output = y * z\n",
    "        output = self.out_proj(output) # (B, D)\n",
    "\n",
    "        # prepare cache for next call\n",
    "        inputs = torch.cat([inputs[:, :, 1:], x_cache], dim=2) # (B, ED, d_conv-1)\n",
    "        cache = (h, inputs)\n",
    "        \n",
    "        return output, cache\n",
    "\n",
    "    def ssm_step(self, x, h):\n",
    "        # x : (B, ED)\n",
    "        # h : (B, ED, N)\n",
    "\n",
    "        # y : (B, ED)\n",
    "        # h : (B, ED, N)\n",
    "\n",
    "        A = -torch.exp(self.A_log.float()) # (ED, N) # todo : ne pas le faire tout le temps, puisque c'est indépendant de la timestep\n",
    "        D = self.D.float()\n",
    "        # TODO remove .float()\n",
    "\n",
    "        deltaBC = self.x_proj(x) # (B, dt_rank+2*N)\n",
    "\n",
    "        delta, B, C = torch.split(deltaBC, [self.config.dt_rank, self.config.d_state, self.config.d_state], dim=-1) # (B, dt_rank), (B, N), (B, N)\n",
    "        delta = F.softplus(self.dt_proj(delta)) # (B, ED)\n",
    "\n",
    "        deltaA = torch.exp(delta.unsqueeze(-1) * A) # (B, ED, N)\n",
    "        deltaB = delta.unsqueeze(-1) * B.unsqueeze(1) # (B, ED, N)\n",
    "\n",
    "        BX = deltaB * (x.unsqueeze(-1)) # (B, ED, N)\n",
    "\n",
    "        if h is None:\n",
    "            h = torch.zeros(x.size(0), self.config.d_inner, self.config.d_state, device=deltaA.device) # (B, ED, N)\n",
    "\n",
    "        h = deltaA * h + BX # (B, ED, N)\n",
    "\n",
    "        y = (h @ C.unsqueeze(-1)).squeeze(2) # (B, ED, N) @ (B, N, 1) -> (B, ED, 1)\n",
    "\n",
    "        y = y + D * x\n",
    "\n",
    "        # todo : pq h.squeeze(1) ??\n",
    "        return y, h.squeeze(1)\n",
    "\n",
    "# taken straight from https://github.com/johnma2006/mamba-minimal/blob/master/model.py\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec5a42d-7a8a-4d5b-a941-70ae1b04bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needs nasdaq data link api to function.\n",
    "\n",
    "#import nasdaqdatalink  as ndl\n",
    "#ndl.ApiConfig.api_key  = 'API KEY'\n",
    "\n",
    "def refreshData():\n",
    "    spy = ndl.get_table('SHARADAR/SFP', ticker=['SPY'],date = { 'gte': '1996-01-01', 'lte': f'{current_date}' })\n",
    "    sp = pd.DataFrame(spy)\n",
    "    sp = sp.drop(columns=['closeunadj','lastupdated','ticker'])\n",
    "    sp = sp.sort_values(by='date', ascending=True)\n",
    "    # Convert data types spy\n",
    "    sp['date'] = pd.to_datetime(sp['date'])\n",
    "    sp['open'] = sp['open'].astype(float)\n",
    "    sp['high'] = sp['high'].astype(float)\n",
    "    sp['low'] = sp['low'].astype(float)\n",
    "    sp['close'] = sp['close'].astype(float)\n",
    "    sp['OHLC'] = round((sp['open']+sp['high']+sp['low']+sp['close'])/4,2)\n",
    "    sp = sp[['date','OHLC']]\n",
    "    sp = sp[1:]\n",
    "    sp.to_csv('SPY.csv')\n",
    "    for i in tickerList:\n",
    "        data = ndl.get_table('SHARADAR/SEP', ticker=[i],date = { 'gte': '1996-01-01', 'lte': f'{current_date}' })\n",
    "        df = pd.DataFrame(data)\n",
    "        #df.reset_index(inplace=True)\n",
    "        df = df.drop(columns=['closeunadj','lastupdated','ticker'])\n",
    "        df = df.sort_values(by='date', ascending=True)\n",
    "        # Convert data types\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['open'] = df['open'].astype(float)\n",
    "        df['high'] = df['high'].astype(float)\n",
    "        df['low'] = df['low'].astype(float)\n",
    "        df['close'] = df['close'].astype(float)\n",
    "        df = pd.merge(df, sp, on='date', how='outer')\n",
    "        #print(df.info())\n",
    "        last_date_str = df.iloc[-1]['date']  # Adjust the column name if necessary\n",
    "        #last_date = datetime.strptime(last_date_str, '%Y-%m-%d')\n",
    "        # Adjust the date format if necessary\n",
    "        daily_info = r.get_fundamentals('SPY')\n",
    "        quote = r.get_quotes('SPY')\n",
    "        copen = daily_info[0]['open']\n",
    "        high = daily_info[0]['high']\n",
    "        low = daily_info[0]['low']\n",
    "        close = quote[0]['last_trade_price']\n",
    "        OHLC = round((float(copen) + float(high) + float(low) + float(close))/4,2)\n",
    "        daily_info = r.get_fundamentals(i)\n",
    "        quote = r.get_quotes(i)\n",
    "            #build row of today's data\n",
    "        date = quote[0]['venue_last_trade_time']\n",
    "        copen = daily_info[0]['open']\n",
    "        high = daily_info[0]['high']\n",
    "        low = daily_info[0]['low']\n",
    "        close = quote[0]['last_trade_price']\n",
    "        volume = daily_info[0]['volume']\n",
    "        new_row = pd.DataFrame({\n",
    "        'date': [current_date.date()],\n",
    "        'open': [copen],\n",
    "        'high': [high],\n",
    "        'low': [low],\n",
    "        'close': [close],\n",
    "        'closeadj': [close],\n",
    "        'volume': [volume],\n",
    "        'OHLC': [OHLC]\n",
    "        })\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        df['open'] = df['open'].astype(float)\n",
    "        df['high'] = df['high'].astype(float)\n",
    "        df['low'] = df['low'].astype(float)\n",
    "        df['close'] = df['close'].astype(float)\n",
    "        #df = df.ffill()\n",
    "        #df = df.bfill()\n",
    "        df['change'] = round(df['close'].shift(1) - df['close'],2)\n",
    "        df['pct_chg'] = round((df['change'] / df['close'].shift(1)) * 100, 2)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        nstd=[]\n",
    "        pstd=[]\n",
    "        lin_reg=[]\n",
    "        for s in range(100,len(df['date'])):\n",
    "            x = df['date'].iloc[s-100:s].index\n",
    "            y = np.round(df['close'].iloc[s-100:s].values,2)\n",
    "            m,c,*_= stats.linregress(x,y)\n",
    "            y_fit = m * x + c\n",
    "            lin_reg.append(y_fit[-1])\n",
    "        df = df[100:]\n",
    "        print(len(df))\n",
    "        df['linreg']= lin_reg\n",
    "        df['test'] = df['linreg'] / df['linreg'].shift(1)\n",
    "        print(len(df))\n",
    "        df = df[df['test'] <= 1.04]\n",
    "        df = df[df['test'] >= .93]\n",
    "        print(len(df))\n",
    "        df = df.drop(columns=['test'])\n",
    "        df.to_csv(f'{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "634edab2-c19e-4f8d-adc6-2fe488e1868b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "num=225\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--use-cuda', default=True,\n",
    "                    help='CUDA training.')\n",
    "parser.add_argument('--seed', type=int, default=1, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.004,\n",
    "                    help='Learning rate.')\n",
    "parser.add_argument('--wd', type=float, default=1e-5,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=64,#16 best = 32 64\n",
    "                    help='Dimension of representations')\n",
    "parser.add_argument('--layer', type=int, default=16, #2 best = 8 16\n",
    "                    help='Num of layers')\n",
    "parser.add_argument('--n-test', type=int, default=num+2,#300\n",
    "                    help='Size of test set')\n",
    "parser.add_argument('--ts-code', type=str, default=\"COST\",\n",
    "                    help='Stock code')                    \n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.cuda = args.use_cuda and torch.cuda.is_available()\n",
    "\n",
    "def evaluation_metric(y_test,y_hat):\n",
    "    global MSE\n",
    "    MSE = mean_squared_error(y_test, y_hat)\n",
    "    RMSE = MSE**0.5\n",
    "    MAE = mean_absolute_error(y_test,y_hat)\n",
    "    R2 = r2_score(y_test,y_hat)\n",
    "    print('%.4f %.4f %.4f %.4f' % (MSE,RMSE,MAE,R2))\n",
    "    \n",
    "\n",
    "def set_seed(seed,cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "def dateinf(series, n_test):\n",
    "    lt = len(series)\n",
    "    #print('Training start',series[0])\n",
    "    #print('Training end',series[lt-n_test-1])\n",
    "    #print('Testing start',series[lt-n_test])\n",
    "    #print('Testing end',series[lt-1])\n",
    "\n",
    "set_seed(args.seed,args.cuda)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,in_dim,out_dim):\n",
    "        super().__init__()\n",
    "        self.config = MambaConfig(d_model=args.hidden, n_layers=args.layer)\n",
    "        self.mamba = nn.Sequential(\n",
    "            nn.Linear(in_dim,args.hidden),\n",
    "            Mamba(self.config),\n",
    "            nn.Linear(args.hidden,out_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.mamba(x)\n",
    "        return x.flatten()\n",
    "\n",
    "def PredictWithData(trainX, trainy, testX):\n",
    "    clf = Net(len(trainX[0]),1)\n",
    "    opt = torch.optim.Adam(clf.parameters(),lr=args.lr,weight_decay=args.wd)\n",
    "    xt = torch.from_numpy(trainX).float().unsqueeze(0)\n",
    "    xv = torch.from_numpy(testX).float().unsqueeze(0)\n",
    "    yt = torch.from_numpy(trainy).float()\n",
    "    if args.cuda:\n",
    "        clf = clf.cuda()\n",
    "        xt = xt.cuda()\n",
    "        xv = xv.cuda()\n",
    "        yt = yt.cuda()\n",
    "    \n",
    "    for e in range(args.epochs):\n",
    "        clf.train()\n",
    "        z = clf(xt)\n",
    "        loss = F.mse_loss(z,yt)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        #if e%10 == 0 and e!=0:#print('Epoch %d | Lossp: %.4f' % (e, loss.item()))    \n",
    "    clf.eval()\n",
    "    mat = clf(xv)\n",
    "    if args.cuda: mat = mat.cpu()\n",
    "    yhat = mat.detach().numpy().flatten()\n",
    "    return yhat\n",
    "def scanLoop():\n",
    "    global data1, finalpredicted_stock_price, data, rdf\n",
    "    buylist = []\n",
    "    selllist = []\n",
    "    rdf = pd.DataFrame()\n",
    "    rtic = []\n",
    "    rscr = []\n",
    "    predList= []\n",
    "    openlist = {}\n",
    "    account = r.load_account_profile()\n",
    "    holdings = r.account.build_holdings()\n",
    "    bp = account['margin_balances']['unallocated_margin_cash']\n",
    "    amount = round(float(bp) / 10 ,2)  \n",
    "    print('\\n Amount per stock: '+str(amount))\n",
    "    for symbol,stock in holdings.items(): \n",
    "        print(symbol, stock['quantity'])\n",
    "        openlist[symbol] = stock['quantity']\n",
    "    for i in tqdm(tickerList):\n",
    "        data = pd.read_csv(i+'.csv')\n",
    "        data['date'] = pd.to_datetime(data['date'], format='%Y-%m-%d')\n",
    "        close = data.pop('close').values\n",
    "        ratechg = data['pct_chg'].apply(lambda x:0.01*x).values\n",
    "        data.drop(columns=['change','pct_chg'],inplace=True)\n",
    "        dat = data.iloc[:,2:].values\n",
    "        trainX, testX = dat[:-args.n_test, :], dat[-args.n_test:, :]\n",
    "        trainy = ratechg[:-args.n_test]\n",
    "        predictions = PredictWithData(trainX, trainy, testX)\n",
    "        time = data['date'][-args.n_test:]\n",
    "        data1 = close[-args.n_test:]\n",
    "        finalpredicted_stock_price = []\n",
    "        pred = close[-args.n_test-1]\n",
    "        for l in range(args.n_test):\n",
    "            pred = close[-args.n_test-1+l]*(1+predictions[l])\n",
    "            finalpredicted_stock_price.append(pred)\n",
    "        dateinf(data['date'],args.n_test)\n",
    "        print('MSE RMSE MAE R2')\n",
    "        evaluation_metric(data1, finalpredicted_stock_price)\n",
    "        rtic.append(i)\n",
    "        rscr.append(round(MSE/data1[-1],3)) #score = MSE / price because smaller prices = smaller mse\n",
    "        predList.append(finalpredicted_stock_price[-1]-data1[-1]) #pred = model's predicted change\n",
    "        print(i)\n",
    "        if data1[-1] < data['linreg'].iloc[-1]:\n",
    "            print('below') #prints below if price is below linreg of last 100 days\n",
    "        if i not in openlist:#buy\n",
    "            if data1[-1] > finalpredicted_stock_price[-1] and data1[-2] < finalpredicted_stock_price[-2] and data1[-1] < data['linreg'].iloc[-1]:\n",
    "                print(f'buy signal on {i}')\n",
    "                #order = r.orders.order_buy_fractional_by_price(i, amount, timeInForce='gfd', extendedHours=False, jsonify=True)\n",
    "                continue\n",
    "        if i in openlist:#sellsig\n",
    "            if data1[-1] > data['linreg'].iloc[-1] and finalpredicted_stock_price[-1] > data1[-1] and data1[-2] > finalpredicted_stock_price[-2]:\n",
    "                print(f'sell signal on {i}')\n",
    "                #sell = r.orders.order_sell_fractional_by_quantity(i, openlist[i]) \n",
    "\n",
    "    \n",
    "    rdf['ticker']=rtic\n",
    "    rdf['score']=rscr\n",
    "    rdf['pred']=predList\n",
    "    print(rdf.head().sort_values(by='score', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a10fef1-5a7f-4bd7-a586-24c59d1deb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Amount per stock: 1502.23\n",
      "MSFT 0.00721600\n",
      "VOO 35.10973100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:17,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE RMSE MAE R2\n",
      "7.1029 2.6651 2.0231 0.9854\n",
      "AMZN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:17<00:08,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE RMSE MAE R2\n",
      "79.5136 8.9170 6.3255 0.9924\n",
      "COST\n",
      "below\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:25<00:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE RMSE MAE R2\n",
      "6.5341 2.5562 1.7447 0.9793\n",
      "GOOGL\n",
      "below\n",
      "  ticker  score      pred\n",
      "2  GOOGL  0.036  2.946664\n",
      "0   AMZN  0.037 -0.750879\n",
      "1   COST  0.093 -3.756961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#refreshData() --only works with ndl api\n",
    "scanLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6578f05e-1424-42b3-9b31-714b36f06120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing GOOGL\n",
      "open date =  2023-08-28 00:00:00 Buyprice = 131.01\n",
      "\n",
      "close date = 2023-09-01 00:00:00 close price =  135.66 net =  517.75\n",
      "open date =  2023-09-25 00:00:00 Buyprice = 131.11\n",
      "\n",
      "close date = 2023-10-10 00:00:00 close price =  138.06 net =  545.19\n",
      "open date =  2023-10-23 00:00:00 Buyprice = 136.5\n",
      "\n",
      "close date = 2023-11-24 00:00:00 close price =  136.69 net =  545.95\n",
      "open date =  2023-12-05 00:00:00 Buyprice = 130.99\n",
      "\n",
      "close date = 2023-12-26 00:00:00 close price =  141.52 net =  589.84\n",
      "open date =  2024-02-01 00:00:00 Buyprice = 141.16\n",
      "\n",
      "close date = 2024-02-12 00:00:00 close price =  147.53 net =  616.46\n",
      "open date =  2024-02-20 00:00:00 Buyprice = 141.12\n",
      "\n",
      "close date = 2024-03-19 00:00:00 close price =  147.03 net =  642.27\n",
      "open date =  2024-06-20 00:00:00 Buyprice = 176.3\n",
      "\n",
      "close date = 2024-06-26 00:00:00 close price =  183.88 net =  669.89\n",
      "open date =  2024-07-01 00:00:00 Buyprice = 182.99\n",
      "\n",
      "close date = 2024-07-08 00:00:00 close price =  189.03 net =  692.0\n",
      "open date =  2024-07-15 00:00:00 Buyprice = 186.53\n",
      "Strategy profit: 38.92%\n",
      " Strategy profit: 38.40%\n"
     ]
    }
   ],
   "source": [
    "#Backtest (uses last stock selected in tickerlist)\n",
    "print(f'testing {rdf['ticker'].iloc[-1]}')\n",
    "net = 500\n",
    "openPrice = 0\n",
    "openShort = 0\n",
    "for i in range(-num,-1):\n",
    "    if openPrice == 0:#buy\n",
    "        if data1[i] > finalpredicted_stock_price[i] and data1[i-1] < finalpredicted_stock_price[i-1] and data1[i] < data['linreg'].iloc[i]:#price goes above pred\n",
    "            openPrice = net / data1[i]\n",
    "            print('open date = ', data['date'].iloc[i], 'Buyprice =', data1[i])\n",
    "            continue\n",
    "    if openPrice != 0:#sell\n",
    "        if data1[i] > data['linreg'].iloc[i] and finalpredicted_stock_price[i] > data1[i] and data1[i-1] > finalpredicted_stock_price[i-1]:#pred goes below price\n",
    "            net = data1[i]*openPrice\n",
    "            print('\\nclose date =', data['date'].iloc[i], 'close price = ', data1[i],'net = ',round(net,2))\n",
    "            openPrice = 0\n",
    "\n",
    "\n",
    "print(f'Strategy profit: {(data1[-1]/data1[-num])*100-100:.2f}%')\n",
    "print(f' Strategy profit: {(net/500)*100-100 :.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
